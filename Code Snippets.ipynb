{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    n_cols = []\n",
    "    for i in range(len(df.columns)):\n",
    "        n_cols.append(df.columns[i].lower().replace(' ', '_'))\n",
    "    df.columns = n_cols\n",
    "    \n",
    "    lst = ['distance','consume','temp_inside']\n",
    "    for col in lst:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column using conditions from other column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if (row['ticker'] == 'SYP') | (row['ticker'] == 'DOW') | (row['ticker'] == 'NASDAQ') :\n",
    "        return 'Stock Market '\n",
    "    elif (row['ticker'] == 'EURUSD') | (row['ticker'] == 'JPYUSD') | (row['ticker'] == 'DXY') | (row['ticker'] == 'VIX') :\n",
    "        return 'Currency'\n",
    "    elif (row['ticker'] == 'GOLD') | (row['ticker'] == 'WTI') :\n",
    "        return 'Commodities'\n",
    "    else:\n",
    "        return 'Bond'\n",
    "df['Asset Class'] = df.apply(categorize, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if (row['ticker'] == 'SYP') | (row['ticker'] == 'DOW') | (row['ticker'] == 'NASDAQ') | (row['ticker'] == 'VIX') :\n",
    "        return 'High Risk '\n",
    "    elif (row['ticker'] == 'EURUSD') | (row['ticker'] == 'JPYUSD') | (row['ticker'] == 'WTI'):\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "df['Risk'] = df.apply(categorize, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a git ignore file\n",
    "\n",
    "$ touch .gitignore\n",
    "-- Names of files to ignore goes in ignore file\n",
    "$ git rm -r --cached .        #untrack files\n",
    "$ git add .                   #re-adding the files\n",
    "$ git commit -m \"issue fixed\" #commiting changes\n",
    "$ git push                    #pushing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a certain number of commits\n",
    "\n",
    "The important part is the “2 commits”! From here, go ahead and type in:\n",
    "    \n",
    "$ git reset HEAD~<HOWEVER MANY COMMITS YOU WERE BEHIND>\n",
    "\n",
    "So, for the example above, one would type:\n",
    "$ git reset HEAD~2\n",
    "\n",
    "After you typed that, your “git status” should say:\n",
    "On branch master Your branch is up to date with ‘origin/master’.\n",
    "nothing to commit, working tree clean\n",
    "Now, you can push the commit again. Yay.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to GitHub\n",
    "\n",
    "To save to the GitHub:\n",
    "in TERMINAL:\n",
    "make sure you are in the Repo Directory.  Use cd until you are there.\n",
    "git add .\n",
    "git commit -m ‘comment about push’\n",
    "git push\n",
    "Go to GITHUB Repo\n",
    "copy the URL from the top of the page\n",
    "Go to STUDENT PORTAL submission page\n",
    "paste the Github URL to submit\n",
    "Hope this helps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show hidden files (git)\n",
    "hidden git files:\n",
    "Command, Shift, and Period keys at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to bin elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tcm = df3[\"total claim amount\"].max()\n",
    "min_tcm = df3['total claim amount'].min()\n",
    "\n",
    "# print(max_tcm)\n",
    "# print(min_tcm)\n",
    "# 2893.239678\n",
    "# 0.099007\n",
    "#This func transforms a column of \n",
    "#\"continuous\" variable into bins, with some params as inpouts. \n",
    "#I couldn't find the way of soft code the bin labels, so I hard coded them :)\n",
    "\n",
    "\n",
    "\n",
    "def categorize(col,min_val,max_val):\n",
    "    \n",
    "    bins = np.linspace(min_val, max_val,10)\n",
    "    return pd.cut(col, bins, labels=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "df4 = categorize(df3['total claim amount'],0,3000)\n",
    "print(df4)\n",
    "\n",
    "df3['claim_bins'] = df4\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to split into cat and num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include=object)\n",
    "numerical = df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_continuous(df):\n",
    "    discrete_lst = []\n",
    "    continuous_lst = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) < (df.shape[0] * 0.01):\n",
    "            discrete_lst.append(col)\n",
    "        else:\n",
    "            continuous_lst.append(col)\n",
    "    return (discrete_lst, continuous_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening a zip file in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "  \n",
    "# specifying the zip file name\n",
    "file_name = \"Orders.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "  \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall()\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.Points == df.Points.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to combine values in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo(row):\n",
    "    if pd.isna(row['Type 2']):\n",
    "        return row['Type 1']\n",
    "    else:\n",
    "        return (row['Type 1'] + '-' + row['Type 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to snake column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    cols.append(data.columns[i].lower().replace(' ', '_'))\n",
    "data.columns = cols\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to plot multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical.columns:\n",
    "    sns.distplot(numerical[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = model_data.corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(10,8))\n",
    "ax=sns.heatmap(correlations, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test/split with shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print('X_train shape is:',X_train.shape)\n",
    "print('y_train shape is:', y_train.shape)\n",
    "print('X_test shape is:', X_test.shape)\n",
    "print('y_train shape is:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodes columns with lists as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special features need to be lists to use\n",
    "X_train_cat['special_features'] = X_train_cat['special_features'].str.split(',')\n",
    "X_train_cat = X_train_cat.drop('special_features',1).join(X_train_cat.special_features.str.join('|').str.get_dummies())\n",
    "X_train_cat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explodes special features into separate rows\n",
    "sakila = sakila.assign(special_features=sakila.special_features.str.split(\",\")).explode('special_features')\n",
    "sakila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(s.apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Ordinal Encoding (with Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical[\"coverage\"] = categorical[\"coverage\"].map({\"Basic\" : 0, \"Extended\" :.5, \"Premium\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler().fit(X_train_num)\n",
    "X_train_norm = transformer.transform(X_train_num)\n",
    "print(X_train_norm.shape)\n",
    "X_train_num_scale = pd.DataFrame(X_train_norm, index = X_train_num.index, columns=X_train_num.columns)\n",
    "X_train_num_scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE for imbalanced data code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(training_x, training_y):\n",
    "\n",
    "    smote = SMOTE(random_state = 100, k_neighbors = 3)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_resample(training_x, training_y)\n",
    "\n",
    "    return X_train_scaled_SMOTE, y_train_SMOTE    \n",
    "\n",
    "X_train_SMOTE, y_train_SMOTE = over_sampling(X_train, y_train)\n",
    "X_test_SMOTE, y_test_SMOTE = over_sampling(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sm = SMOTE(random_state=100,k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train_scaled,y_train)\n",
    "\n",
    "X_train_SMOTE.shape\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test_scaled)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))\n",
    "precision:  0.49388523047977423\n",
    "recall:  0.7332402234636871\n",
    "f1:  0.5902192242833052\n",
    "\n",
    "predictions = classification.predict(X_test_scaled)\n",
    "classification.score(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder to be used on new data later.\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(X_cat)\n",
    "\n",
    "cols = encoder.get_feature_names(input_features=X_cat.columns)\n",
    "\n",
    "X_cat_encode = pd.DataFrame(encoder.transform(X_cat).toarray(),columns=cols)\n",
    "\n",
    "X_cat_encode.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation codes R2, MSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train R2: {} -- test R2: {}'.format(linreg.score(X_train, y_train),\n",
    "                                            linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "train_mse=mse(linreg.predict(X_train), y_train)\n",
    "test_mse=mse(linreg.predict(X_test), y_test)\n",
    "\n",
    "print ('train MSE: {} -- test MSE: {}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train RMSE: {} -- test RMSE: {}'.format(train_mse**.5, test_mse**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "train_mae=mae(linreg.predict(X_train), y_train)\n",
    "test_mae=mae(linreg.predict(X_test), y_test)\n",
    "\n",
    "print ('train MAE: {} -- test MAE: {}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X, y):\n",
    "    #Finds and prints the metrics of the algorithm\n",
    "    predictions = lm.predict(X)\n",
    "    r2 = r2_score(y, predictions)\n",
    "    print('R2:', r2)\n",
    "    mse = np.sqrt(mean_squared_error(y,predictions))\n",
    "    print('MSE:', mse)\n",
    "    rmse = math.sqrt(mse)\n",
    "    print('RMSE:', rmse)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run multiple models to compare outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define function to run all models\n",
    "def models_automation(models, X_train, y_train):\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [LinearRegression(),SGDRegressor(),KNeighborsRegressor(), MLPRegressor(),DecisionTreeRegressor(),RandomForestRegressor()]\n",
    "models_automation(model_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for time/date transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_encoding(table):\n",
    "    #The input table needs to have a column 'effective_to_date'\n",
    "    table['month'] = table['effective_to_date'].dt.month\n",
    "    table['weekday'] = table['effective_to_date'].dt.day\n",
    "    table = table.drop('effective_to_date',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logreg.predict(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding by definition\n",
    "# accuracy = TP+TN / all\n",
    "#precision = TP / (TP+FP)\n",
    "#recall = TP / (TP+FN)\n",
    "#f1_scores = 2*(precision * recall)/(precision+recall)\n",
    "real_accuracy = \n",
    "accuracy = (5+139)/(5+5+51+139)\n",
    "precision = 5/(5+5)\n",
    "recall = 5/(5+51)\n",
    "f1 = 2*(precision * recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy = ', accuracy)\n",
    "print('precision = ', precision)\n",
    "print('recall = ', recall)\n",
    "print('f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy = ', accuracy_score(y_test, prediction))\n",
    "print('precision = ', precision_score(y_test, prediction))\n",
    "print('recall = ', recall_score(y_test, prediction))\n",
    "print('f1 = ', f1_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('name_of_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "tags = ['h1', 'p']\n",
    "text = [element.text for element in soup.find_all(tags)][2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def slice_per(source, step):\n",
    "      return [source[i::step] for i in range(step)]\n",
    "    \n",
    "newer_list =slice_per(new,3)\n",
    "\n",
    "final_list = newer_list[0:2:]\n",
    "\n",
    "final_list[1][0]\n",
    "\n",
    "result = []\n",
    "for i in range(len(final_list[0])):\n",
    "         element = final_list[0][i] + ' (' + final_list[1][i] + ')'  \n",
    "         result.append(element)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "html = requests.get(url).content\n",
    "image = soup.find_all('img')\n",
    "text = str(image)\n",
    "\n",
    "pattern = '//upload.wikimedia.org[\\w*-_./]*'\n",
    "list_links = re.findall(pattern,text)           \n",
    "\n",
    "list_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBI Most Wanted Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url).content\n",
    "tags = ['h3']\n",
    "soup =BeautifulSoup(html,\"lxml\")\n",
    "text =[element.text for element in soup.find_all(tags)]\n",
    "\n",
    "text\n",
    "just_names = []\n",
    "for item in text:\n",
    "    x = item.strip()\n",
    "    just_names.append(x)\n",
    "\n",
    "    \n",
    "just_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Playlist URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('https://api.spotify.com/v1/playlists/{playlist_id}/tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = hot_100['song'].str.lower()\n",
    "top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.choice(hot_100['song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = input('Please enter song title:  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = song.lower()\n",
    "print(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if song in list(top_100):\n",
    "    print('your song \"' + song +'\" in the list top 100!')\n",
    "    print('recommendation to listen:  ' + random.choice(hot_100['song']))\n",
    "else:\n",
    "    print('your song \"' + song +'\"\" not in the list top 100, sorry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_song, data):\n",
    "    import random\n",
    "    random_index = random.choice(range(data.shape[0]))\n",
    "    if user_song.lower() in list(data['song'].str.lower()):\n",
    "        print('your song \"' + song +'\" is in the top 100!')\n",
    "        print('recommendation to listen: \"{}\" by {}'.format(data.loc[random_index]['song'], data.loc[random_index]['artist']))\n",
    "    else:\n",
    "        print('your song \"' + song +'\"\" not in the list top 100, sorry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = input('Please enter song title:  ')\n",
    "recommend(song, hot_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvp():\n",
    "    song_input = input('Please fill in the title of a song you like :')\n",
    "    top_100_check = popvortex_100[popvortex_100['title'] == song_input]\n",
    "    if len(top_100_check['title']) == 0 :\n",
    "        return 'Sorry, this song is not part of the PopVortex Top 100 at the moment.'\n",
    "    else :\n",
    "        for i in range(4):   # I want to avod here to suggest the same song the user just filled in.\n",
    "            # I plan 4 loops, but the probability the random choice ends three times on the initial user input is almost zero.\n",
    "            index = randint(1,100)\n",
    "            proposed_title = popvortex_100['title'][index]\n",
    "            if proposed_title != song_input:\n",
    "                break\n",
    "        proposed_artist = popvortex_100['artist'][index]\n",
    "        output = 'Great choice ! This song in in the PopVortex Top 100. You should listen to ' + proposed_title + ' by ' + proposed_artist + '. You might like it !'\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To print entire things and not truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "array = np.arange(10001)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = churn[churn['Churn'] == 'No']\n",
    "category_1 = churn[churn['Churn'] == 'Yes']\n",
    "\n",
    "category_0_undersampled = resample(category_0, \n",
    "                              replace=False, \n",
    "                              n_samples = len(category_1))\n",
    "\n",
    "data_downsampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1, \n",
    "                                  replace=True, \n",
    "                                  n_samples = len(category_0))\n",
    "\n",
    "data_upsampled = pd.concat([category_0, category_1_oversampled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['original', 'uppsampled', 'downsampled']\n",
    "accuracy = [og_accuracy, u_accuracy, d_accuracy]\n",
    "accuracy = pd.DataFrame([accuracy], columns = model).T\n",
    "accuracy.columns = ['accuracy score']\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"String_Split_multi_columns.png\" width=\"500\" height=500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SplitString](String_Split_multi_columns.png =100x100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np.where to convert columns to 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['response_rate'] = np.where(data2.response=='Yes',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def detect_outlier(data):\n",
    "    # find q1 and q3 values\n",
    "    q1, q3 = np.percentile(sorted(data), [25, 75])\n",
    " \n",
    "    # compute IRQ\n",
    "    iqr = q3 - q1\n",
    " \n",
    "    # find lower and upper bounds\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    " \n",
    "    outliers = [x for x in data if x <= lower_bound or x >= upper_bound]\n",
    " \n",
    "    return outliers\n",
    " \n",
    "# input data\n",
    "detect_outlier((data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seetting up axis for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4,ncols=3,figsize=(12,6))\n",
    "ax[0,0].boxplot(data['step'])\n",
    "ax[0,1].boxplot(data['type'])\n",
    "ax[0,2].boxplot(data['amount'])\n",
    "\n",
    "ax[1,0].boxplot(data['nameOrig'])\n",
    "ax[1,1].boxplot(data['oldbalanceOrg'])\n",
    "ax[1,2].boxplot(data['newbalanceOrig'])\n",
    "\n",
    "ax[2,0].boxplot(data['nameDest'])\n",
    "ax[2,1].boxplot(data['oldbalanceDest'])\n",
    "ax[2,2].boxplot(data['newbalanceDest'])\n",
    "\n",
    "ax[3,0].boxplot(data['isFraud'])\n",
    "ax[3,1].boxplot(data['isFlaggedFraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day as 1 month as [1,4,7,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_P2[S_P2['day']==1 & S_P2['month'] isin ['1,4,7,10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different dataframe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jupyter_datatables import init_datatables_mode\n",
    "\n",
    "init_datatables_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
