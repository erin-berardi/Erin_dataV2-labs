{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import BASE_COLORS\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    n_cols = []\n",
    "    for i in range(len(df.columns)):\n",
    "        n_cols.append(df.columns[i].lower().replace(' ', '_'))\n",
    "    df.columns = n_cols\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    lst = ['distance','consume','temp_inside']\n",
    "    for col in lst:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking if NaN values are same index in 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,columns=['first_set','second_set'])\n",
    "\n",
    "nan_values = df[df.isna().any(axis=1)]\n",
    "\n",
    "print (nan_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to get titles rented in may!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a query to get the list of all unique film titles and a boolean indicating if it was rented (rental_date) in May 2005. (Create new column called - 'rented_in_may'). This will be our TARGET (y) variable.\n",
    "query2 = '''SELECT DISTINCT f.title, MAX(IF(r.rental_date BETWEEN '2005-05-01' AND '2005-05-31', 1, 0)) as rented_in_may \n",
    "FROM film f\n",
    "LEFT JOIN inventory i USING (film_id)\n",
    "LEFT JOIN rental r USING (inventory_id)\n",
    "GROUP BY f.title\n",
    "ORDER BY f.title;'''\n",
    "data2 = pd.read_sql_query(query2, engine)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"], format= '%Y-%d-%m %H:%M')\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"], dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Engine to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/{Name of database}'\n",
    "engine = sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(name='table_name', con=engine, schema=None, if_exists='replace', index=False)\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column using conditions from other column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if (row['ticker'] == 'SYP') | (row['ticker'] == 'DOW') | (row['ticker'] == 'NASDAQ') :\n",
    "        return 'Stock Market '\n",
    "    elif (row['ticker'] == 'EURUSD') | (row['ticker'] == 'JPYUSD') | (row['ticker'] == 'DXY') | (row['ticker'] == 'VIX') :\n",
    "        return 'Currency'\n",
    "    elif (row['ticker'] == 'GOLD') | (row['ticker'] == 'WTI') :\n",
    "        return 'Commodities'\n",
    "    else:\n",
    "        return 'Bond'\n",
    "df['Asset Class'] = df.apply(categorize, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if (row['ticker'] == 'SYP') | (row['ticker'] == 'DOW') | (row['ticker'] == 'NASDAQ') | (row['ticker'] == 'VIX') :\n",
    "        return 'High Risk '\n",
    "    elif (row['ticker'] == 'EURUSD') | (row['ticker'] == 'JPYUSD') | (row['ticker'] == 'WTI'):\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "df['Risk'] = df.apply(categorize, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a certain number of commits\n",
    "\n",
    "The important part is the “2 commits”! From here, go ahead and type in:\n",
    "    \n",
    "$ git reset HEAD~<HOWEVER MANY COMMITS YOU WERE BEHIND>\n",
    "\n",
    "So, for the example above, one would type:\n",
    "$ git reset HEAD~2\n",
    "\n",
    "After you typed that, your “git status” should say:\n",
    "On branch master Your branch is up to date with ‘origin/master’.\n",
    "nothing to commit, working tree clean\n",
    "Now, you can push the commit again. Yay.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to GitHub\n",
    "\n",
    "To save to the GitHub:\n",
    "in TERMINAL:\n",
    "make sure you are in the Repo Directory.  Use cd until you are there.\n",
    "git add .\n",
    "git commit -m ‘comment about push’\n",
    "git push\n",
    "Go to GITHUB Repo\n",
    "copy the URL from the top of the page\n",
    "Go to STUDENT PORTAL submission page\n",
    "paste the Github URL to submit\n",
    "Hope this helps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show hidden files (git)\n",
    "hidden git files:\n",
    "Command, Shift, and Period keys at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert to last commit:\n",
    "\n",
    "$ git log --oneline\n",
    "\n",
    "#choose a hashtag/number\n",
    "\n",
    "$ git reset --hard hashtag/number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows all commands.\n",
    "$ git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ git reset #from log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ git reset --hard #of log commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gist on github\n",
    "\n",
    "Go to https://gist.github.com/YOUR-GITHUB-USERNAME/\n",
    "Click ‘New Gist’ on the upper right corner\n",
    "Open the folder in a Finder/Explorer window on your local computer\n",
    "Drag the file into the text box (the ‘code space’). This should fill the space with JSON looking text for the framework of the notebook content.\n",
    "Copy/Paste the full file name (e.g., mynotebook.ipynb) into the filename box, and give a description above.\n",
    "Create the Gist!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a .gitignore file in a repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a git ignore file\n",
    "\n",
    "$ touch .gitignore\n",
    "-- Names of files to ignore goes in ignore file\n",
    "$ git rm -r --cached .        #untrack files\n",
    "$ git add .                   #re-adding the files\n",
    "$ git commit -m \"issue fixed\" #commiting changes\n",
    "$ git push                    #pushing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ touch .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ echo \"name of file or *.csv\" > .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to bin elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tcm = df3[\"total claim amount\"].max()\n",
    "min_tcm = df3['total claim amount'].min()\n",
    "\n",
    "# print(max_tcm)\n",
    "# print(min_tcm)\n",
    "# 2893.239678\n",
    "# 0.099007\n",
    "#This func transforms a column of \n",
    "#\"continuous\" variable into bins, with some params as inpouts. \n",
    "#I couldn't find the way of soft code the bin labels, so I hard coded them :)\n",
    "\n",
    "\n",
    "\n",
    "def categorize(col,min_val,max_val):\n",
    "    \n",
    "    bins = np.linspace(min_val, max_val,10)\n",
    "    return pd.cut(col, bins, labels=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "df4 = categorize(df3['total claim amount'],0,3000)\n",
    "print(df4)\n",
    "\n",
    "df3['claim_bins'] = df4\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to split into cat and num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include=object)\n",
    "numerical = df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for continuous and discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_continuous(df):\n",
    "    discrete_lst = []\n",
    "    continuous_lst = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) < (df.shape[0] * 0.01):\n",
    "            discrete_lst.append(col)\n",
    "        else:\n",
    "            continuous_lst.append(col)\n",
    "    return (discrete_lst, continuous_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_discrete(variable):\n",
    "    unique_values = variable.nunique()\n",
    "    if unique_values > 100:  #len(numerical_df) * 0.02\n",
    "        return 'continuous'\n",
    "        \n",
    "    else:\n",
    "        return 'discrete'\n",
    "\n",
    "deff=numerical_df.apply(continuous_discrete) #.to_frame   will display as dataframe\n",
    "deff\n",
    "\n",
    "customer_lifetime_value          continuous\n",
    "income                           continuous\n",
    "monthly_premium_auto             continuous\n",
    "months_since_last_claim            discrete\n",
    "months_since_policy_inception      discrete\n",
    "number_of_open_complaints          discrete\n",
    "number_of_policies                 discrete\n",
    "total_claim_amount               continuous\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to diff cont to discrete \n",
    "def continuous_discrete(variable):\n",
    "    unique_values = variable.nunique()\n",
    "    if unique_values > 100:\n",
    "        return 'continuous'\n",
    "    else:\n",
    "        return 'discrete'\n",
    "    \n",
    "\n",
    "continuous_df = pd.DataFrame()\n",
    "discrete_df = pd.DataFrame()\n",
    "\n",
    "for column in numerical_df.columns:\n",
    "    if continuous_discrete(numerical_df[column]) == 'continuous':\n",
    "        continuous_df[column] = numerical_df[column]\n",
    "    else:\n",
    "        discrete_df[column] = numerical_df[column]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to plot together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def plot_numerical(df):\n",
    "    num_cols = len(df.columns)\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if df[col].nunique() >= 1:\n",
    "            sns.histplot(x=col, data=df, ax=axs[i//4, i%4])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_numerical(numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=15, figsize=(15, 6), layout=(2, 4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, column in enumerate(data.columns, 1):\n",
    "    plt.subplot(3,4,i)\n",
    "    sns.histplot(data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle saving and reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "\n",
    "pickle.load(open('scaler.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(kmeans, open('kmean.pkl', 'wb'))\n",
    "\n",
    "pickle.load(open('kmean.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening a zip file in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "  \n",
    "# specifying the zip file name\n",
    "file_name = \"Orders.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "  \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall()\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.Points == df.Points.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to combine values in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo(row):\n",
    "    if pd.isna(row['Type 2']):\n",
    "        return row['Type 1']\n",
    "    else:\n",
    "        return (row['Type 1'] + '-' + row['Type 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to snake column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    cols.append(data.columns[i].lower().replace(' ', '_'))\n",
    "data.columns = cols\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to plot multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical.columns:\n",
    "    sns.distplot(numerical[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = model_data.corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(10,8))\n",
    "ax=sns.heatmap(correlations, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test/split with shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print('X_train shape is:',X_train.shape)\n",
    "print('y_train shape is:', y_train.shape)\n",
    "print('X_test shape is:', X_test.shape)\n",
    "print('y_train shape is:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodes columns with lists as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special features need to be lists to use\n",
    "X_train_cat['special_features'] = X_train_cat['special_features'].str.split(',')\n",
    "X_train_cat = X_train_cat.drop('special_features',1).join(X_train_cat.special_features.str.join('|').str.get_dummies())\n",
    "X_train_cat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explodes special features into separate rows\n",
    "sakila = sakila.assign(special_features=sakila.special_features.str.split(\",\")).explode('special_features')\n",
    "sakila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(s.apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Ordinal Encoding (with Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical[\"coverage\"] = categorical[\"coverage\"].map({\"Basic\" : 0, \"Extended\" :.5, \"Premium\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler().fit(X_train_num)\n",
    "X_train_norm = transformer.transform(X_train_num)\n",
    "print(X_train_norm.shape)\n",
    "X_train_num_scale = pd.DataFrame(X_train_norm, index = X_train_num.index, columns=X_train_num.columns)\n",
    "X_train_num_scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE for imbalanced data code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(training_x, training_y):\n",
    "\n",
    "    smote = SMOTE(random_state = 100, k_neighbors = 3)\n",
    "    X_train_scaled_SMOTE, y_train_SMOTE = smote.fit_resample(training_x, training_y)\n",
    "\n",
    "    return X_train_scaled_SMOTE, y_train_SMOTE    \n",
    "\n",
    "X_train_SMOTE, y_train_SMOTE = over_sampling(X_train, y_train)\n",
    "X_test_SMOTE, y_test_SMOTE = over_sampling(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sm = SMOTE(random_state=100,k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train_scaled,y_train)\n",
    "\n",
    "X_train_SMOTE.shape\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test_scaled)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))\n",
    "precision:  0.49388523047977423\n",
    "recall:  0.7332402234636871\n",
    "f1:  0.5902192242833052\n",
    "\n",
    "predictions = classification.predict(X_test_scaled)\n",
    "classification.score(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder to be used on new data later.\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(X_cat)\n",
    "\n",
    "cols = encoder.get_feature_names(input_features=X_cat.columns)\n",
    "\n",
    "X_cat_encode = pd.DataFrame(encoder.transform(X_cat).toarray(),columns=cols)\n",
    "\n",
    "X_cat_encode.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation codes R2, MSE, MAE - linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train R2: {} -- test R2: {}'.format(linreg.score(X_train, y_train),\n",
    "                                            linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "train_mse=mse(linreg.predict(X_train), y_train)\n",
    "test_mse=mse(linreg.predict(X_test), y_test)\n",
    "\n",
    "print ('train MSE: {} -- test MSE: {}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train RMSE: {} -- test RMSE: {}'.format(train_mse**.5, test_mse**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "train_mae=mae(linreg.predict(X_train), y_train)\n",
    "test_mae=mae(linreg.predict(X_test), y_test)\n",
    "\n",
    "print ('train MAE: {} -- test MAE: {}'.format(train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X, y):\n",
    "    #Finds and prints the metrics of the algorithm\n",
    "    predictions = lm.predict(X)\n",
    "    r2 = r2_score(y, predictions)\n",
    "    print('R2:', r2)\n",
    "    mse = np.sqrt(mean_squared_error(y,predictions))\n",
    "    print('MSE:', mse)\n",
    "    rmse = math.sqrt(mse)\n",
    "    print('RMSE:', rmse)\n",
    "    mae = mean_absolute_error(y, predictions)\n",
    "    print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to run multiple models to compare outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define function to run all models\n",
    "def models_automation(models, X_train, y_train):\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [LinearRegression(),SGDRegressor(),KNeighborsRegressor(), MLPRegressor(),DecisionTreeRegressor(),RandomForestRegressor()]\n",
    "models_automation(model_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for time/date transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_encoding(table):\n",
    "    #The input table needs to have a column 'effective_to_date'\n",
    "    table['month'] = table['effective_to_date'].dt.month\n",
    "    table['weekday'] = table['effective_to_date'].dt.day\n",
    "    table = table.drop('effective_to_date',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logreg.predict(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding by definition\n",
    "# accuracy = TP+TN / all\n",
    "#precision = TP / (TP+FP)\n",
    "#recall = TP / (TP+FN)\n",
    "#f1_scores = 2*(precision * recall)/(precision+recall)\n",
    "real_accuracy = \n",
    "accuracy = (5+139)/(5+5+51+139)\n",
    "precision = 5/(5+5)\n",
    "recall = 5/(5+51)\n",
    "f1 = 2*(precision * recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy = ', accuracy)\n",
    "print('precision = ', precision)\n",
    "print('recall = ', recall)\n",
    "print('f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy = ', accuracy_score(y_test, prediction))\n",
    "print('precision = ', precision_score(y_test, prediction))\n",
    "print('recall = ', recall_score(y_test, prediction))\n",
    "print('f1 = ', f1_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "LR_confusion_matrix = confusion_matrix(y_test,pred)\n",
    "LR_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('name_of_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "tags = ['h1', 'p']\n",
    "text = [element.text for element in soup.find_all(tags)][2:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Playlist URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('https://api.spotify.com/v1/playlists/{playlist_id}/tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = hot_100['song'].str.lower()\n",
    "top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.choice(hot_100['song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if song in list(top_100):\n",
    "    print('your song \"' + song +'\" in the list top 100!')\n",
    "    print('recommendation to listen:  ' + random.choice(hot_100['song']))\n",
    "else:\n",
    "    print('your song \"' + song +'\"\" not in the list top 100, sorry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_song, data):\n",
    "    import random\n",
    "    random_index = random.choice(range(data.shape[0]))\n",
    "    if user_song.lower() in list(data['song'].str.lower()):\n",
    "        print('your song \"' + song +'\" is in the top 100!')\n",
    "        print('recommendation to listen: \"{}\" by {}'.format(data.loc[random_index]['song'], data.loc[random_index]['artist']))\n",
    "    else:\n",
    "        print('your song \"' + song +'\"\" not in the list top 100, sorry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = input('Please enter song title:  ')\n",
    "recommend(song, hot_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To print entire things and not truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "array = np.arange(10001)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = churn[churn['Churn'] == 'No']\n",
    "category_1 = churn[churn['Churn'] == 'Yes']\n",
    "\n",
    "category_0_undersampled = resample(category_0, \n",
    "                              replace=False, \n",
    "                              n_samples = len(category_1))\n",
    "\n",
    "data_downsampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1, \n",
    "                                  replace=True, \n",
    "                                  n_samples = len(category_0))\n",
    "\n",
    "data_upsampled = pd.concat([category_0, category_1_oversampled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['original', 'uppsampled', 'downsampled']\n",
    "accuracy = [og_accuracy, u_accuracy, d_accuracy]\n",
    "accuracy = pd.DataFrame([accuracy], columns = model).T\n",
    "accuracy.columns = ['accuracy score']\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"String_Split_multi_columns.png\" width=\"500\" height=500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SplitString](String_Split_multi_columns.png =100x100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np.where to convert columns to 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['response_rate'] = np.where(data2.response=='Yes',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def detect_outlier(data):\n",
    "    # find q1 and q3 values\n",
    "    q1, q3 = np.percentile(sorted(data), [25, 75])\n",
    " \n",
    "    # compute IRQ\n",
    "    iqr = q3 - q1\n",
    " \n",
    "    # find lower and upper bounds\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    " \n",
    "    outliers = [x for x in data if x <= lower_bound or x >= upper_bound]\n",
    " \n",
    "    return outliers\n",
    " \n",
    "# input data\n",
    "outliers = detect_outlier((data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Outliers with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['windspeed']:\n",
    "    q75,q25 = np.percentile(BIKE.loc[:,x],[75,25])\n",
    "    intr_qr = q75-q25\n",
    " \n",
    "    max = q75+(1.5*intr_qr)\n",
    "    min = q25-(1.5*intr_qr)\n",
    " \n",
    "    BIKE.loc[BIKE[x] < min,x] = np.nan\n",
    "    BIKE.loc[BIKE[x] > max,x] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute the missing values with Mean, median or Knn imputed values.\n",
    "# Drop the null values (if the proportion is comparatively less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To drop outliers or rows conditionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['column']= outliers].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.score < 50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df.score < 50) & (df.score > 20)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seetting up axis for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4,ncols=3,figsize=(12,6))\n",
    "ax[0,0].boxplot(data['step'])\n",
    "ax[0,1].boxplot(data['type'])\n",
    "ax[0,2].boxplot(data['amount'])\n",
    "\n",
    "ax[1,0].boxplot(data['nameOrig'])\n",
    "ax[1,1].boxplot(data['oldbalanceOrg'])\n",
    "ax[1,2].boxplot(data['newbalanceOrig'])\n",
    "\n",
    "ax[2,0].boxplot(data['nameDest'])\n",
    "ax[2,1].boxplot(data['oldbalanceDest'])\n",
    "ax[2,2].boxplot(data['newbalanceDest'])\n",
    "\n",
    "ax[3,0].boxplot(data['isFraud'])\n",
    "ax[3,1].boxplot(data['isFlaggedFraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day as 1 month as [1,4,7,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_P2[S_P2['day']==1 & S_P2['month'] isin ['1,4,7,10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different dataframe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jupyter_datatables import init_datatables_mode\n",
    "\n",
    "init_datatables_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill space with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.replace(\" \", np.NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
