{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "# mnist = fetch_mldata('MNIST original')\n",
    "# X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X= fetch_openml('mnist_784')['data']\n",
    "y= fetch_openml('mnist_784')['target']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f95aff63510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "plt.imshow(X[36000].reshape(28,28),cmap=matplotlib.cm.binary,interpolation = 'nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = np.where(y_train == '5', 1, 0)\n",
    "y_test_5 =np.where(y_test == '5', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model_5 = LogisticRegression().fit(X_train,y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_5 = model_5.predict(X_test)\n",
    "acc = accuracy_score(y_test_5, y_pred_5)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   4. 149. 255. 184.  12.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  11. 133. 212. 253. 253. 253. 102.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 162. 236. 253. 253. 253. 253. 253.  55.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 196.\n",
      " 253. 253. 253. 253. 253. 253. 239.  18.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 249. 253.\n",
      " 253. 253. 185. 253. 253. 177.  24.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 129. 247. 253. 253.\n",
      " 165. 150. 205. 253. 139.   3.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 247. 253. 240. 131.\n",
      "  85. 221. 253. 253.  84.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   4. 187. 253. 253. 236. 139.\n",
      " 252. 253. 253. 253.  84.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  21. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 248.  53.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  99. 253. 253. 253. 253. 253.\n",
      " 214. 253. 253. 179.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   4. 186. 251. 253. 249. 172.\n",
      " 133. 253. 253. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  49.  94.   6.   0.\n",
      " 212. 253. 253.  39.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 126.\n",
      " 253. 253. 197.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  27. 234.\n",
      " 253. 253.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 100. 253.\n",
      " 253. 239.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  61. 249. 253.\n",
      " 253.  79.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5. 109. 253. 253.\n",
      " 193.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  66. 253. 253. 253.\n",
      "  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 147. 253. 253. 182.\n",
      "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  99. 248. 253. 222.  13.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It predicted NOT a 5,  which is correct'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model_5.predict(X_train)\n",
    "print(X_train[36000], y_pred_train[36000])\n",
    "'''It predicted NOT a 5,  which is correct'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_test,y_test_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_5C = never_5_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test_5, y_pred_5C)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   4. 149. 255. 184.  12.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  11. 133. 212. 253. 253. 253. 102.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 162. 236. 253. 253. 253. 253. 253.  55.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 196.\n",
      " 253. 253. 253. 253. 253. 253. 239.  18.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 249. 253.\n",
      " 253. 253. 185. 253. 253. 177.  24.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 129. 247. 253. 253.\n",
      " 165. 150. 205. 253. 139.   3.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  89. 247. 253. 240. 131.\n",
      "  85. 221. 253. 253.  84.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   4. 187. 253. 253. 236. 139.\n",
      " 252. 253. 253. 253.  84.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  21. 253. 253. 253. 253. 253.\n",
      " 253. 253. 253. 248.  53.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  99. 253. 253. 253. 253. 253.\n",
      " 214. 253. 253. 179.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   4. 186. 251. 253. 249. 172.\n",
      " 133. 253. 253. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  49.  94.   6.   0.\n",
      " 212. 253. 253.  39.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 126.\n",
      " 253. 253. 197.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  27. 234.\n",
      " 253. 253.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 100. 253.\n",
      " 253. 239.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  61. 249. 253.\n",
      " 253.  79.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   5. 109. 253. 253.\n",
      " 193.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  66. 253. 253. 253.\n",
      "  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 147. 253. 253. 182.\n",
      "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  99. 248. 253. 222.  13.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.] [False]\n"
     ]
    }
   ],
   "source": [
    "y_pred_trainC = never_5_clf.predict(X_train)\n",
    "print(X_train[36000], y_pred_train[36000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54153,   426],\n",
       "       [  905,  4516]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921948001978783"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall = TP/(TP+FN)\n",
    "recall = 54153/(54153+426)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835627883323041"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision = TP / TP+FP\n",
    "precision = 54153/(54153+905)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878599377947226"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_scores = 2*(precision * recall)/(precision+recall)\n",
    "f1 = 2*(precision * recall)/(precision+recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Metrics for the never 5 classification.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [ 5421,     0]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_5,y_pred_trainC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90965"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision = TP / TP+FP\n",
    "precisionC = 54579/(54579+5421)\n",
    "precisionC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall = = TP/(TP+FN)\n",
    "recallC = 54579/(54579+0)\n",
    "recallC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9526876652789777"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_scores = 2*(precision * recall)/(precision+recall)\n",
    "f1C = 2*(precisionC*recallC)/(precisionC+recallC)\n",
    "f1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7f95c6999dd0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_roc_curve(estimator, X, y,)\n",
    "#roc_curve(y_train_5, y_pred_train)\n",
    "plot_roc_curve(model_5,X_train,y_train_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Never5Classifier should be a binary classifer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-a0ada621810a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_trainC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnever_5_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_plot/roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[0;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         estimator.__class__.__name__))\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     prediction_method = _check_classifer_response_method(estimator,\n",
      "\u001b[0;31mValueError\u001b[0m: Never5Classifier should be a binary classifer"
     ]
    }
   ],
   "source": [
    "roc_curve(y_train_5,y_pred_trainC)\n",
    "plot_roc_curve(never_5_clf,X_train,y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9126257159078305"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_pred_train)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train_5, y_pred_trainC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The logistic regression model works best.  It is 91% accurate the Never5Classifier is like \n",
    "flipping a coin.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
